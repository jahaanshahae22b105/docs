---
title: "Waves Speech-to-Text (STT)"
description: "Quickly convert spoken audio into text using Waves STT."
---

# Transcribe audio with Waves Speech-to-Text (STT)

Convert audio to accurate, timestamped text in one API call. Supports file uploads (multipart), remote audio URLs, and common audio formats (**`wav`**, **`mp3`**, **`m4a`**). Designed for quick integration into transcription pipelines and apps.

## Endpoint

- **URL:** `https://api.waves.smallest.ai/v1/stt/transcribe`
- **Method:** `POST`

<Note>
  **Note:** This example endpoint is the recommended integration pattern â€” use your workspace or environment-specific base URL.
</Note>

## Required headers

| Header                                                              | Value                                           | Description                                 |
| :------------------------------------------------------------------ | :---------------------------------------------- | :------------------------------------------ |
| <Badge icon="lock" color="blue">Authorization</Badge>               | `Bearer <YOUR_API_KEY>`                         | Required for authentication.                |
| <Badge icon="table-of-contents" color="orange">Content-Type</Badge> | `multipart/form-data` **OR** `application/json` | Use `multipart` for files, `json` for URLs. |
| <Badge icon="circle-check" color="green">Accept</Badge>             | `application/json`                              | Standard response format.                   |


<RequestExample>

```python Sample Request
import requests

url = "[https://waves-api.smallest.ai/api/v1/transcribe](https://waves-api.smallest.ai/api/v1/transcribe)"
headers = {"Authorization": "Bearer YOUR_API_KEY"}
files = {"file": open("audio.wav", "rb")}
data = {"language": "en"}

response = requests.post(url, headers=headers, files=files, data=data)
print(response.json())
```

</RequestExample>

<Tip>
  **Tip:** For the best transcription accuracy, we recommend using **16kHz .wav files**. This ensures the audio is uncompressed and retains the highest fidelity for the model.
</Tip>

<ResponseExample>

```json Sample Response
{
  "request_id": "req_01F3X2Y7ZABCDEF",
  "status": "completed",
  "model": "whisper-large",
  "language": "en",
  "transcript": "Good morning everyone. Today we'll talk about the product roadmap...",
  "confidence": 0.91,
  "segments": [
    {
      "start": 0.34,
      "end": 3.20,
      "text": "Good morning everyone.",
      "confidence": 0.95
    },
    {
      "start": 3.21,
      "end": 9.50,
      "text": "Today we'll talk about the product roadmap and next steps.",
      "confidence": 0.90
    }
  ],
  "duration_seconds": 120.4
}
```

</ResponseExample>

## Common parameters

| Parameter                 | Type / Example Value             | Description                                                         |
| :------------------------ | :------------------------------- | :------------------------------------------------------------------ |
| **`model`**               | `whisper-small`, `whisper-large` | Model identifier. Choose a larger model for **better accuracy**.    |
| **`language`**            | ISO Code (e.g., `en`, `es`)      | ISO language code. If omitted, the service may **auto-detect**.     |
| **`enable_punctuation`**  | `true` / `false`                 | Instructs the service to insert **punctuation and capitalization**. |
| **`profanity_filter`**    | `true` / `false`                 | Instructs the service to **mask or remove profanities**.            |
| **`speaker_diarization`** | `true` / `false`                 | If supported, enables returning **speaker labels** within segments. |

<Tip>
  **Tip:** If you receive a 401/403, verify your API key and that it has STT scope enabled.
</Tip>